% Generated by roxygen2 (4.1.1): do not edit by hand
% Please edit documentation in R/datasets.R
\docType{data}
\name{wt16}
\alias{wt16}
\alias{wt16.docs}
\alias{wt16.docs.metadata}
\alias{wt16.vocab}
\title{A subset of the Whales and Tires dataset}
\format{\code{wt16.vocab} a vector of unique words in the corpus vocabulary.

\code{wt16.docs} a list of documents in the corpus. Each item (represents a
 document) is a matrix (2 X U) of word frequencies, where U represents the
 number of unique words in a document. Each column in the matrix represents
 a unique word in a document and contains
 \itemize{
   \item vocabulary-id. the index of the word in the vocabulary (starts with 0)
   \item frequency. the relative frequency of the word in the document
 }

\code{wt16.docs.metadata} a matrix of document (article) metadata, where each
row represents a document with
 \itemize{
   \item category. the Wikipedia category assigned to the article
   \item title. the title of the Wikipedia web article
 }}
\source{
The Wikipedia articles are downloaded from the
 \href{http://en.wikipedia.org/wiki/Main_Page}{English Wikipedia}
 with the help of
 \href{http://www.mediawiki.org/wiki/API:Main_page}{Media Wiki} API.
}
\usage{
\code{data(wt16.vocab)}
\code{data(wt16.docs)}
\code{data(wt16.docs.metadata)}
}
\description{
A subset of Wikipedia artricles under the Wikipedia categories
\href{http://en.wikipedia.org/wiki/Category:Whales}{Whales}
and \href{http://en.wikipedia.org/wiki/Category:Tires}{Tires}
formatted for running the LDA Gibbs sampling algorithms. This
dataset contains 16 Wikipedia articles.
}
\author{
Clint P. George, November 11, 2015
}
\seealso{
Other datasets: \code{\link{bop}}, \code{\link{bop.docs}},
  \code{\link{bop.docs.metadata}}, \code{\link{bop.vocab}};
  \code{\link{whales}}, \code{\link{whales.docs}},
  \code{\link{whales.docs.metadata}},
  \code{\link{whales.vocab}}; \code{\link{wt}},
  \code{\link{wt.docs}}, \code{\link{wt.docs.metadata}},
  \code{\link{wt.vocab}}
}

