% Generated by roxygen2: do not edit by hand
% Please edit documentation in R/datasets.R
\docType{data}
\name{wt}
\alias{wt}
\alias{wt.docs}
\alias{wt.docs.metadata}
\alias{wt.vocab}
\title{The Whales and Tires dataset}
\format{\code{wt.vocab} a vector of unique words in the corpus vocabulary.
 
\code{wt.docs} a list of documents in the corpus. Each item (represents a 
 document) is a matrix (2 X U) of word frequencies, where U represents the 
 number of unique words in a document. Each column in the matrix represents 
 a unique word in a document and contains    
 \itemize{
   \item vocabulary-id. the index of the word in the vocabulary (starts with 0)  
   \item frequency. the relative frequency of the word in the document   
 }      
 
\code{wt.docs.metadata} a matrix of document (article) metadata, where each 
row represents a document with        
 \itemize{
   \item category. the Wikipedia category assigned to the article 
   \item title. the title of the Wikipedia web article     
 }}
\source{
The Wikipedia articles are downloaded from the 
 \href{http://en.wikipedia.org/wiki/Main_Page}{English Wikipedia}
 with the help of 
 \href{http://www.mediawiki.org/wiki/API:Main_page}{Media Wiki} API.
}
\usage{
\code{data(wt.vocab)}
\code{data(wt.docs)}
\code{data(wt.docs.metadata)}
}
\description{
A subset of Wikipedia artricles under the Wikipedia categories  
\href{http://en.wikipedia.org/wiki/Category:Whales}{Whales} 
and \href{http://en.wikipedia.org/wiki/Category:Tires}{Tires} 
formatted for running the LDA Gibbs sampling algorithms. This 
dataset contains 84 Wikipedia articles.
}
\author{
Clint P. George, April 15, 2014
}
\seealso{
Other datasets: \code{\link{bop}}, \code{\link{whales}},
  \code{\link{wt16}}
}

